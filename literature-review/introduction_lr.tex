\section{Introduction} \label{sec:literature-review-introduction}
The aim of this chapter is to carry out a review of recent, relevant literature with the objective of clarifying the main concepts relating to the field of explainable AI, to gain a picture of how researchers have approached these and, most importantly, to identify current trends and gaps.

The chapter is organised as follows:
\begin{itemize}
  \item Section \ref{sec:explainability} aims to clarify the concept of \textit{explainability}, which is central to the field of explainable AI and to every further discussion.
  \item Section \ref{sec:importance-of-explainability} investigates which may be the reasons for the importance assigned to explainability by our contemporary societies.
  \item Section \ref{sec:evaluation-of-explainability} is an overview of the main methods that have been proposed to measure explainability.
  \item Section \ref{sec:explainability-in-bayesian-networks} will focus on an assessment of the concepts discussed in the previous sections, as applied specifically to Bayesian networks.
  \item Section \ref{sec:explaining-the-most-probable-explanation} offers a review of a recent paper by \citet{Butz2018} and connects it to the aforementioned notions.
  The reason for this analysis, is because the paper constitutes an important reference for the work carried out in this thesis since it will be the starting point for the developed methodology.
\end{itemize}

Throughout the chapter, various gaps that are present in the literature will be identified and assessed; these will be summarised coherently in Section \ref{sec:literature-review-summary}.