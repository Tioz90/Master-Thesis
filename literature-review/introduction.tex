\section{Introduction} \label{sec:literature-review-introduction}
This chapter aims to carry out a review of recent, relevant literature with the aim of clarifying the main concepts relating to the field of Explainable AI, give a feel of how researchers have approached these and, most importantly, identify current trends and gaps.

The chapter is organised as follows:
\begin{itemize}
  \item Section \ref{sec:explainability} aims to clarify the concept of \textit{explainability}, that is central to the field of Explainable AI and to every further discussion.
  \item Section \ref{sec:importance-of-explainability} investigates the reasons for the importance assigned to explainability in our contemporary societies.
  \item Section \ref{sec:evaluation-of-explainability} is an overview of the main methods that have been proposed to measure explainability.
  \item Section \ref{sec:explainability-in-bayesian-networks} will focus on an assessment of the previous concepts as applied specifically to Bayesian Networks.
  \item Section \ref{sec:explaining-the-most-probable-explanation} offers a review of a recent paper by \citet{Butz2018} and connects it to aforementioned notions.
  The reason for this analysis, is that this paper is an important reference for the work carried out in this thesis as it will be the starting point of the methodology.
\end{itemize}

Throughout the chapter, various gaps that are present in the literature will be identified and assessed; these will be summarised in a coherent fashion in Section \ref{sec:literature-review-summary}.