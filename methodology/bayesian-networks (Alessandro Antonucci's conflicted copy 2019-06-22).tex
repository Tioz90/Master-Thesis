% !TEX root = thesis-thomas-tiotto.tex

\section{Bayesian Networks}
Bayesian Networks (BN) are a class of Probabilistic Graphical Models that are used to represent systems under conditions of uncertainty.
To give a formal definition we will first need a few basic concepts from probability and graph theory.

\subsubsection{Probability distributions}
A \textit{probability distribution} is a function $\mathbb{P}: \mathcal{S} \rightarrow \mathbb{R}$ with $\mathcal{S}$ a set of \textit{events} of interest.  
To be a valid probability distribution $\mathbb{P}$ must satisfy:
\begin{itemize}
	\item $\mathbb{P}(\sigma) \geq 0 \quad \forall \sigma \in \mathcal{S}$
	\item $\sum_{\sigma} = 1 \quad \forall \sigma \in \mathcal{S}$
	\item $\alpha, \beta \in \mathcal{S} \wedge \alpha \cap \beta=\emptyset 	\Rightarrow \mathbb{P}(\alpha \cup \beta)=\mathbb{P}(\alpha)+\mathbb{P}(\beta)$
\end{itemize}
Each event $\sigma \in \mathcal{S}$ must have a probability $\mathbb{P}(\sigma) \in [0,1]$ and the sum of all these must equal $1$.  
An event with $P(\sigma) = 0$ is deemed \textit{impossible} while one with $\mathbb{P}(\sigma) = 1$ is \textit{certain}.

There is some discord regarding how to actually \textit{interpret} the probability of an event.
What I believe to be the initially commonly held view is the \textit{frequentist} one, that views the probability of an event as the ratio of times it would occur over a great number of trials.  
So, for example, saying that obtaining a heads has probability $0.5$ when tossing a coin would mean that over repeated throws we would observe heads half the time.

Another, commonly held view is the \textit{Bayesian} (from the 18th century mathematician Thomas Bayes) one in which probabilities are viewed as the \textit{subjective} degree of belief attributable regarding the manifestation of an event.
In this interpretation, stating that a coin has $0.5$ probability of landing on heads simply means that the person making the claim personally believes that the chances of seeing heads of tails are the same.
This is obviously a ``softer'' definition compared to the frequentist one but it is nonetheless useful in that it lets one characterise certain events that haven't come about yet or are liable to happen only once or a few times.

Philosophically, Bayesian inference assigns a probability to a hypothesis (a \textit{prior}) while the frequentist method tests a raw hypothesis empirically before assigning it any probability.
As Bayesian inference naturally embraces and deals with uncertainty, it is an enormously useful tool to model and reason about the real, stochastic world we live in.

\subsubsection{Random variables}
\textit{Random variables} are a way of bringing to the fore the attributes of interest of events while dealing with them in a clean, mathematical way.
The values that a random variable can take are a function of the events in sample space $\mathcal{S}$, each of these is assigned a value by the random variable function.
I will only be dealing with \textit{categorical random variables} i.e. those who's codomain is a discrete set of values.
Every random variable has a probability distribution induced by the cardinality of the subsets of its values; in the case of categorical-valued one, such a distribution is \textit{multinomial}.

\subsubsection{Conditional probabilities}
After having defined the basic notion of probability, we can construe one the basic building blocks of Bayesian Networks: the concept of \textit{conditional probability} $\mathbb{P}(\beta|\alpha)$, ``the probability of event $\beta$ given event $\alpha$'':
\begin{equation} \label{eq:conditionalprobability}
\mathbb{P}(\beta|\alpha) = \frac{\mathbb{P}(\beta \cap \alpha)}{\mathbb{P}(\alpha)}
\end{equation}
is the relative proportion of event $\beta$ compared to event $\alpha$ and intuitively represents the probability of $\beta$ \textit{knowing} that $\alpha$ has already occurred.

Equation \ref{eq:conditionalprobability} can be easily manipulated to obtain another basic element of Bayesian Networks: what is called the \textit{chain rule of conditional probabilities}:
\begin{equation} \label{eq:chainrule}
	\mathbb{P}(\beta \cap \alpha) = \mathbb{P}(\beta|\alpha) \mathbb{P}(\alpha)
\end{equation}
This can be generalised to any number of events:
\begin{equation} \label{eq:chainrule}
	\mathbb{P}(\alpha_1 \cap \ldots \cap \alpha_n) = \mathbb{P}(\alpha_n | \alpha_1 \cap \ldots \cap \alpha_{n-1}) \ldots \mathbb{P}(\alpha_1 | \alpha_2 ) \mathbb{P}(\alpha_1) 
\end{equation}
Intuitively, it means that we can decompose joint probabilities as products of conditional probabilities.  
As we'll see, this is how the values in a Bayesian Network are calculated.

\subsubsection{Independence}
Now, we have just seen in Equation \ref{eq:conditionalprobability} that, in general, $\mathbb{P}(\beta | \alpha) \neq \mathbb{P}(\alpha)$ because $\mathbb{P}(\beta \cap \alpha) \neq \mathbb{P}(\beta) \mathbb{P}(\alpha)$.
If 
\begin{equation}
	\mathbb{P}(\beta | \alpha) = \mathbb{P}(\beta)
\end{equation}
 we say that events $\alpha$ and $\beta$ are \textit{unconditionally independent} or simply \textit{independent}.
This means that knowing that $\alpha$ took place doesn't change our beliefs around $\beta$ happening. 
In the real world it is hard, or actually impossible if we consider existence at a fine-enough level to involve Chaos Theory, to find two such perfectly non-interacting events.
Thus, a more useful concept is that of \textit{conditional independence} where two previously dependent event become independent when also conditioned on a third one:
\begin{equation}
	\mathbb{P}(\beta | \alpha \cap \gamma ) = \mathbb{P}(\beta)
\end{equation}

\subsubsection{Graphs}
Many problems in Machine Learning (ML) don't involve classification or prediction of single data points in isolation, but of set of entities that may present a more, or less, complex relation with each other. 
Most real-world phenomena fit into the latter framework.
Graphs are one of the most powerful tools for the modelling of this class of problems, as their structure naturally captures the wide variety of relations that may exist between entities.
These range from the atomical structure of a molecule to a social network of friends.  
In both these examples graphs help in reasoning, visualising and making inferences and predictions.

Formally, A graph is a tuple 
\begin{equation}
	\mathcal{G} = (\mathcal{V}, \mathcal{E})
\end{equation}
with $\mathcal{V} = \{ v_1 \ldots v_n \}$ the set of \textit{vertices} and $\mathcal{E} = \mathcal{V} \times \mathcal{V}$ the set of \textit{edges}.
For our scopes, we will only be considering the case where every element in $\mathcal{E}$ is a pair either of the form $(v_i, v_j)$ or $(v_j, v_i)$ with $i \neq j$.  
That is to say that the class of graphs presently of interest for us are those where there can be at most a single directed edge between any node in $\mathcal{V}$ and no self-loops.
We are also interested in enforcing that there be no \textit{cycles} in the graph, i.e. sequences of nodes of the form $v_i \rightarrow v_j \rightarrow \cdots \rightarrow v_i$.
The resulting graph possessing only directed edges and no cycles is commonly called a \textit{directed acyclic graph}, or DAG for short.  
This data structure is of paramount importance as it's the fundamental graphical representation used for Bayesian Networks.

\subsubsection{Polytrees}
We now have all elements to be able to formally define a Bayesian Network.
I will also define polytrees and trees because these are a fundamental concept for the work carried out in this thesis.

A \textit{loop} is a trace $v_i, v_j \ldots v_i$ of nodes obtained by following edges regardless of their direction; a directed graph containing no such traces is called a \textit{polytree}.  
A \textit{tree} is a particular case of polytree where each node has at most one parent.

\subsubsection{Bayesian Networks}
A Bayesian Network (BN) is represented graphically by a DAG where each vertex corresponds to a random variable $X_i$ and the edges model the dependencies among these.
Such a model is basically a way of compactly representing an explicit joint distribution $\mathbb{P}(X_1 \cap \ldots \cap X_n) = \mathbb{P}(X_1) \ldots \mathbb{P}(X_n)$, that is factorised into $\mathbb{P}(X_n | X_1 \cap \ldots \cap X_{n-1}) \ldots \mathbb{P}(X_1 | X_2 ) \mathbb{P}(X_1) $.
The way this compactness is achieved is in exploiting the independencies that exist among the random variables.
A full probability table for a joint distribution of random variables obscures the independencies and requires an exponential number of entries for the representation.
A Bayesian Network on the other hand can represent the same distribution using only a linear number of parameters.

One nice characteristic of BNs is that they very naturally model the type of mixed causal and stochastic processes that we find in all of Nature.
Imagine we want to represent the process modelled by joint distribution $\mathbb{P}(B,A) = \mathbb{P}(B) \mathbb{P}(A)$; using the chain rule for conditional probabilities (Eq. \ref{eq:chainrule}) we can write this as $\mathbb{P}(B|A) \mathbb{P}(A)$.
A BN modelling this process would be composed of two nodes $A$ and $B$ with an edge from the former to the latter $A \rightarrow B$, $A$ is called the ``parent'' of $B$.  Each of these two nodes would have its own probability table, with $\mathbb{P}(A)$ representing the \textit{prior} distribution over $A$ and $\mathbb{P}(B|A)$ the \textit{conditional probability distribution} of $B$ given $A$.
We can now see why these types of models are named \textit{Bayesian} Networks: the inference process starts with a given prior distribution/belief.
causaluty





\subsection{Inferences/updating}
\subsection{Maximum a posteriori estimation}
\todo{simple queries, MAP queries}
\subsection{Most probable explanation}
\todo{special case of MAP}
\section{Information theory}
\subsection{Entropy}
\subsection{Normalised entropy}