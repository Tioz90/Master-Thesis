\section{Introduction} \label{sec:mathematical-background-introduction}
This chapter will arrive to give a formal definition of Bayesian Networks, a class of Probabilistic Graphical Models that are used to represent systems under conditions of uncertainty.

The chapter is organised as follows:
\begin{itemize}
  \item Section \ref{sec:probability-theory} introduces a series of basic concepts from Probability Theory focusing mainly on the basic concept of random variables and also establishing the notions of conditioning, independency and correlation.
  \item Section \ref{sec:information-theory} presents information entropy and uses it to define measures for random variables, \textit{Kullback-Leibler divergence}, and distance measures for other objects, \textit{Hamming and Jaccard distances}.
  \item Section \ref{sec:graph-theory} introduces the objects of graphs and polytrees and the central concept of \textit{d-separation}.
  \item Section \ref{sec:bayesiannetworks} uses the content of the previous sections to define the Bayesian Network formalism and then gives an overview of structure learning algorithms and the notions of \textit{conditional probability and maximum a posteriori queries}.
\end{itemize}

Not all the concepts introduced in this chapter are strictly needed for the description of the Bayesian Network formalism, but all will be useful as a mathematical reference for the methods developed in later chapters of this thesis.